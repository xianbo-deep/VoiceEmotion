dataset:
  base_path : ./dataset
  emotions: ["Angry","Happy","Sad","Surprise","Neutral"]
  processed_data : ./dataset/emotion.csv


model:
  model_name : facebook/wav2vec2-base
  layer:
    dim : 768
    num_emotions: 5


training:
  metric_for_best_model: eval_overall_f1
  warmup_ratio : 0
  load_best_model_at_end: true
  lora_checkpoints: ./lora_checkpoints
  per_device_train_batch_size: 32
  per_device_eval_batch_size: 32
  num_train_epochs: 10
  eval_steps : 50
  eval_strategy: steps
  save_steps : 100
  save_strategy: steps
  report_to: tensorboard
  logging_steps: 10
  learning_rate : 5.0e-5
  fp16 : false
  patience : 5
  gradient_checkpointing: false
  logging_dir : ./logs
  lr_scheduler_type: cosine
  max_grad_norm: 1.0
  weight_decay: 0.01


loraconfig:
  r : 16
  lora_alpha : 32
  lora_dropout: 0.01
  bias : none
  target_modules: ["q_proj", "v_proj","k_proj"]
